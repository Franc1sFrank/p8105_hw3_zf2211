P8105\_hw3\_zf2211
================
Francis
10/10/2018

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
    ## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
    ## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
    ## ✔ readr   1.1.1     ✔ forcats 0.3.0

    ## ── Conflicts ────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

Problem 1
=========

``` r
#read data
library(p8105.datasets)
data(brfss_smart2010, package = "p8105.datasets")
```

``` r
#tidy up data
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = as_factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"), ordered = TRUE))
```

In 2002, states

``` r
brfss %>% 
  filter(year == "2002") %>% 
  distinct(locationabbr, locationdesc) %>% 
  count(locationabbr) %>% 
  filter(n == 7)
```

    ## # A tibble: 3 x 2
    ##   locationabbr     n
    ##   <chr>        <int>
    ## 1 CT               7
    ## 2 FL               7
    ## 3 NC               7

were observed at 7 locations.

``` r
#create a dataset for spaghetti plot
brfss1 = brfss %>% 
  group_by(locationabbr, year) %>% 
  distinct(locationdesc) %>% 
  count(locationabbr)
```

``` r
#spaghetti plot
ggplot(brfss1, aes(x = year, y = n, color = locationabbr)) +
  geom_line() +
  geom_point()
```

![](p8105_hw3_zf2211_files/figure-markdown_github/unnamed-chunk-6-1.png) This spaghetti plot shows the number of locations change in each state from 2002 to 2010. As we can see, most states have the similar trend and the change is relatively small, while FL had big fluctuation in 2007 and 2010.

``` r
#filter data
brfss %>% 
  filter(year %in% c("2002", "2006", "2010")) %>% 
  filter(locationabbr == "NY", response == "Excellent") %>% 
  group_by(year) %>% 
  summarize(mean = mean(data_value), 
            sd = sd(data_value)) %>% 
#make a table  
  knitr::kable(digits = 1)
```

|  year|  mean|   sd|
|-----:|-----:|----:|
|  2002|  24.0|  4.5|
|  2006|  22.5|  4.0|
|  2010|  22.7|  3.6|

From the table, the mean of NY "Excellent" response decreased from 24.0%(2002) to 22.5%(2006) and keeps similar to 22.7%(2010). The SD of NY "Excellent" response decreased from 4.5%(2002) to 4.0%(2006) to 3.6%(2010).

``` r
#filter data
brfss_avg = brfss %>% 
  group_by(year, locationabbr, response) %>% 
  summarize(avg_prop = mean(data_value))
#plot histogram
ggplot(brfss_avg, aes(x = year, y = avg_prop, color = locationabbr)) +
  geom_line() +
  labs(x = "Year",
       y = "Average percentage of each response",
       title = "The state-level average percent of each response from 2002 to 2010") +
  facet_grid(. ~ response) + #seperate into 5 groups
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, hjust = 0.8)) +
  guides(colour = guide_legend(nrow = 3)) #row of legend
```

    ## Warning: Removed 1 rows containing missing values (geom_path).

![](p8105_hw3_zf2211_files/figure-markdown_github/unnamed-chunk-8-1.png) As we can see, the percent of each response from high to low is "Very good", "Good", "Excellent", "Fair" and "Poor". But we could check this conclusion later if have spare time.

Problem2
========

``` r
#read data and print
data(instacart, package = "p8105.datasets")
print(instacart)
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord… reordered user_id eval_set
    ##       <int>      <int>            <int>     <int>   <int> <chr>   
    ##  1        1      49302                1         1  112108 train   
    ##  2        1      11109                2         1  112108 train   
    ##  3        1      10246                3         0  112108 train   
    ##  4        1      49683                4         0  112108 train   
    ##  5        1      43633                5         1  112108 train   
    ##  6        1      13176                6         0  112108 train   
    ##  7        1      47209                7         0  112108 train   
    ##  8        1      22035                8         1  112108 train   
    ##  9       36      39612                1         0   79431 train   
    ## 10       36      19660                2         1   79431 train   
    ## # ... with 1,384,607 more rows, and 9 more variables: order_number <int>,
    ## #   order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

``` r
#summary
summary(instacart)
```

    ##     order_id         product_id    add_to_cart_order   reordered     
    ##  Min.   :      1   Min.   :    1   Min.   : 1.000    Min.   :0.0000  
    ##  1st Qu.: 843370   1st Qu.:13380   1st Qu.: 3.000    1st Qu.:0.0000  
    ##  Median :1701880   Median :25298   Median : 7.000    Median :1.0000  
    ##  Mean   :1706298   Mean   :25556   Mean   : 8.758    Mean   :0.5986  
    ##  3rd Qu.:2568023   3rd Qu.:37940   3rd Qu.:12.000    3rd Qu.:1.0000  
    ##  Max.   :3421070   Max.   :49688   Max.   :80.000    Max.   :1.0000  
    ##     user_id         eval_set          order_number      order_dow    
    ##  Min.   :     1   Length:1384617     Min.   :  4.00   Min.   :0.000  
    ##  1st Qu.: 51732   Class :character   1st Qu.:  6.00   1st Qu.:1.000  
    ##  Median :102933   Mode  :character   Median : 11.00   Median :3.000  
    ##  Mean   :103113                      Mean   : 17.09   Mean   :2.701  
    ##  3rd Qu.:154959                      3rd Qu.: 21.00   3rd Qu.:5.000  
    ##  Max.   :206209                      Max.   :100.00   Max.   :6.000  
    ##  order_hour_of_day days_since_prior_order product_name      
    ##  Min.   : 0.00     Min.   : 0.00          Length:1384617    
    ##  1st Qu.:10.00     1st Qu.: 7.00          Class :character  
    ##  Median :14.00     Median :15.00          Mode  :character  
    ##  Mean   :13.58     Mean   :17.07                            
    ##  3rd Qu.:17.00     3rd Qu.:30.00                            
    ##  Max.   :23.00     Max.   :30.00                            
    ##     aisle_id     department_id      aisle            department       
    ##  Min.   :  1.0   Min.   : 1.00   Length:1384617     Length:1384617    
    ##  1st Qu.: 31.0   1st Qu.: 4.00   Class :character   Class :character  
    ##  Median : 83.0   Median : 8.00   Mode  :character   Mode  :character  
    ##  Mean   : 71.3   Mean   : 9.84                                        
    ##  3rd Qu.:107.0   3rd Qu.:16.00                                        
    ##  Max.   :134.0   Max.   :21.00

Instacart dataset contains 1384617 observations and 15 variables.

Problem3
========

``` r
data(ny_noaa, package = "p8105.datasets")
#read data
```
